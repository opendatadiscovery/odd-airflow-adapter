version: '3.2'
networks:
  airflow:

services:
  postgres:
    image: postgres:13.1
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_DB=airflow
      - POSTGRES_PASSWORD=airflow
      - PGDATA=/var/lib/postgresql/data/pgdata
    # ports:
    #   - 5432:5432
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./docker/database/data:/var/lib/postgresql/data/pgdata
      - ./docker/database/logs:/var/lib/postgresql/data/log
    command: >
     postgres
       -c listen_addresses=*
       -c logging_collector=on
       -c log_destination=stderr
       -c max_connections=200
    networks:
      - airflow
  mysql:
    image: mysql:5.7
    container_name: airflow_db
    environment:
        - MYSQL_ROOT_PASSWORD=root
        - MYSQL_DATABASE=airflow
        - MYSQL_USER=airflow
        - MYSQL_PASSWORD=airflow
    command: mysqld --character-set-server=utf8 --collation-server=utf8_unicode_ci
    networks:
      - airflow

  # Hive
  # namenode:
  #   image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
  #   volumes:
  #     - namenode:/hadoop/dfs/name
  #   environment:
  #     - CLUSTER_NAME=test
  #   env_file:
  #     - ./hadoop-hive.env
  #   ports:
  #     - "50070:50070"
  # datanode:
  #   image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
  #   volumes:
  #     - datanode:/hadoop/dfs/data
  #   env_file:
  #     - ./hadoop-hive.env
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:50070"
  #   ports:
  #     - "50075:50075"
  # hive-server:
  #   image: bde2020/hive:2.3.2-postgresql-metastore
  #   env_file:
  #     - ./hadoop-hive.env
  #   environment:
  #     HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
  #     SERVICE_PRECONDITION: "hive-metastore:9083"
  #   ports:
  #     - "10000:10000"
  # hive-metastore:
  #   image: bde2020/hive:2.3.2-postgresql-metastore
  #   env_file:
  #     - ./hadoop-hive.env
  #   command: /opt/hive/bin/hive --service metastore
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
  #   ports:
  #     - "9083:9083"
  # hive-metastore-postgresql:
  #   image: bde2020/hive-metastore-postgresql:2.3.0
  # presto-coordinator:
  #   image: shawnzhu/prestodb:0.181
  #   ports:
  #     - "8080:8080"
  redis:
    image: redis:5.0.5
    environment:
      REDIS_HOST: redis
      REDIS_PORT: 6379
    ports:
      - 6379:6379
    networks:
      - airflow
  webserver:
    env_file:
      - ./docker/.env
    image: odd_airflow_dev
    ports:
      - 8081:8080
    volumes:
      - ./docker/dags:/opt/airflow/dags
      - ./odd_airflow:/opt/airflow/dags/odd_airflow
      - ./docker/logs:/opt/airflow/logs
      - ./docker/files:/opt/airflow/files
      - /var/run/docker.sock:/var/run/docker.sock
    deploy:
      restart_policy:
        condition: on-failure
        delay: 8s
        max_attempts: 3
    depends_on:
      - postgres
      - mysql
      - redis
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
    networks:
      - airflow
  flower:
    image: odd_airflow_dev
    env_file:
      - ./docker/.env
    ports:
      - 5555:5555
    depends_on:
      - redis
    deploy:
      restart_policy:
        condition: on-failure
        delay: 8s
        max_attempts: 3
    volumes:
      - ./docker/logs:/opt/airflow/logs
    command: flower
    networks:
      - airflow
  scheduler:
    image: odd_airflow_dev
    env_file:
      - ./docker/.env
    volumes:
      - ./docker/dags:/opt/airflow/dags
      - ./docker/odd_airflow:/opt/airflow/dags/odd_airflow
      - ./docker/logs:/opt/airflow/logs
      - ./docker/files:/opt/airflow/files
      - /var/run/docker.sock:/var/run/docker.sock
    command: scheduler
    depends_on:
      - redis
      - postgres
      - mysql
    deploy:
      restart_policy:
        condition: on-failure
        delay: 8s
        max_attempts: 3
    networks:
      - airflow
  worker:
    image: odd_airflow_dev
    env_file:
      - ./docker/.env
    volumes:
      - ./docker/dags:/opt/airflow/dags
      - ./odd_airflow:/opt/airflow/dags/odd_airflow
      - ./docker/logs:/opt/airflow/logs
      - ./docker/files:/opt/airflow/files
      - /var/run/docker.sock:/var/run/docker.sock
    command: worker
    depends_on:
      - scheduler
    deploy:
      restart_policy:
        condition: on-failure
        delay: 8s
        max_attempts: 3
    networks:
      - airflow
  initdb:
    image: odd_airflow_dev
    env_file:
      - ./docker/.env
    volumes:
      - ./docker/dags:/opt/airflow/dags
      - ./odd_airflow:/opt/airflow/dags/odd_airflow
      - ./docker/logs:/opt/airflow/logs
      - ./docker/files:/opt/airflow/files
      - /var/run/docker.sock:/var/run/docker.sock
    entrypoint: /bin/bash
    deploy:
      restart_policy:
        condition: on-failure
        delay: 8s
        max_attempts: 5
    command: -c "airflow db init"
    depends_on:
      - redis
      - postgres
      - mysql
    networks:
      - airflow

volumes:
  namenode:
  datanode: